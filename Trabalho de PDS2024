# Importar pacotes necessários
import gdown
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import butter, ellip, filtfilt, tf2zpk, freqz
from numpy.fft import fft, fftfreq
from collections import Counter
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import f1_score
from six import StringIO
from IPython.display import Image
import pydotplus

# Baixar e carregar o arquivo do Google Drive
url = 'https://drive.google.com/uc?id=1BIvaGB8cq72hsSdldi7LiNsuv0A7FkPg'
gdown.download(url, 'DogMoveData.csv', quiet=False)
df = pd.read_csv('DogMoveData.csv')

# Calcular normas euclidianas do acelerômetro e giroscópio
df['ANorm'] = np.linalg.norm(df[['ANeck_x', 'ANeck_y', 'ANeck_z']], axis=1)
df['GNorm'] = np.linalg.norm(df[['GNeck_x', 'GNeck_y', 'GNeck_z']], axis=1)

# Visualização de normas
df_aux = df[['t_sec', 'ANorm', 'GNorm']].iloc[:200]
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.title("ANorm x t_sec")
plt.plot(df_aux["t_sec"], df_aux["ANorm"])
plt.subplot(1, 2, 2)
plt.title("GNorm x t_sec")
plt.plot(df_aux["t_sec"], df_aux["GNorm"])
plt.tight_layout()
plt.show()

# Filtragem dos sinais
def apply_filter(data, filter_type='low', cutoff=10, fs=50, order=5):
    b, a = (butter(order, cutoff / (0.5 * fs), btype=filter_type) 
            if filter_type == 'low' else ellip(order, 0.1, 40, cutoff / (0.5 * fs), btype='high'))
    return filtfilt(b, a, data)

# Aplicar filtros e criar novas colunas filtradas
dog_ids = df['DogID'].unique()
for dog_id in dog_ids:
    subset = df[df['DogID'] == dog_id]
    df.loc[subset.index, 'FilteredANorm'] = apply_filter(apply_filter(subset['ANorm'], 'high'), 'low')
    df.loc[subset.index, 'FilteredGNorm'] = apply_filter(apply_filter(subset['GNorm'], 'high'), 'low')

# Visualização dos dados filtrados
df_filt = df[['t_sec', 'FilteredANorm', 'FilteredGNorm']].iloc[:200]
fig, axs = plt.subplots(2, 2, figsize=(11, 7))
fig.suptitle('Comparação antes e após filtros')
axs[0, 0].plot(df_aux['t_sec'], df_aux['ANorm'], 'tab:blue')
axs[0, 0].set_title("ANorm x t_sec")
axs[0, 1].plot(df_filt['t_sec'], df_filt['FilteredANorm'], 'tab:green')
axs[0, 1].set_title("ANorm (filtrada) x t_sec")
axs[1, 0].plot(df_aux['t_sec'], df_aux['GNorm'], 'tab:blue')
axs[1, 0].set_title("GNorm x t_sec")
axs[1, 1].plot(df_filt['t_sec'], df_filt['FilteredGNorm'], 'tab:green')
axs[1, 1].set_title("GNorm (filtrada) x t_sec")
plt.tight_layout()
plt.show()

# Funções para extração de características
def energy(sig): return np.sum(sig ** 2) * 0.01
def peak(sig): return fftfreq(len(sig))[np.argmax(np.abs(fft(sig)))]
def cross_mean(sig): return np.sum(np.diff(np.sign(sig - np.mean(sig))) != 0)

# Janelação e extração de características
def windowing(data, window_size=200, overlap=0.5, window_type='hann'):
    step = int(window_size * (1 - overlap))
    window = np.hanning(window_size) if window_type == 'hann' else np.ones(window_size)
    return [data[i:i + window_size] * window for i in range(0, len(data) - window_size + 1, step)]

# Processamento dos dados por janela
window_size = 200
id, ea, eg, pa, pg, cma, cmg, b = [], [], [], [], [], [], [], []
for dog_id in dog_ids:
    dog = df[df['DogID'] == dog_id]
    a_win = windowing(dog['FilteredANorm'].values, window_size)
    g_win = windowing(dog['FilteredGNorm'].values, window_size)

    for sig_w_a, sig_w_g in zip(a_win, g_win):
        id.append(dog_id)
        ea.append(energy(sig_w_a))
        eg.append(energy(sig_w_g))
        pa.append(peak(sig_w_a))
        pg.append(peak(sig_w_g))
        cma.append(cross_mean(sig_w_a))
        cmg.append(cross_mean(sig_w_g))

df_win = pd.DataFrame({
    'DogID': id, 'Energy_A': ea, 'Energy_G': eg, 
    'Peak_A': pa, 'Peak_G': pg, 'Cross_Mean_A': cma, 'Cross_Mean_G': cmg
})

# Criar novo DataFrame consolidado
df_consolidated = pd.DataFrame({
    'DogID': id, 
    'ANorm': df['ANorm'], 
    'GNorm': df['GNorm'], 
    'FilteredANorm': df['FilteredANorm'], 
    'FilteredGNorm': df['FilteredGNorm'], 
    'Energy_A': ea, 
    'Energy_G': eg, 
    'Peak_A': pa, 
    'Peak_G': pg, 
    'Cross_Mean_A': cma, 
    'Cross_Mean_G': cmg,
    'Model': [None] * len(id), 
    'F1_Score': [None] * len(id)
})

# Classificação usando Decision Tree
df_clf = df_win[df['Behavior'] != '<undefined>']
X = df_clf[['Energy_A', 'Energy_G', 'Peak_A', 'Peak_G', 'Cross_Mean_A', 'Cross_Mean_G']]
y = df_clf['Behavior'].replace({'Galloping': 1, 'Standing': 2, 'Walking': 3})

clf = DecisionTreeClassifier(max_depth=5)
clf.fit(X, y)
f1 = f1_score(y, clf.predict(X), average='weighted')
df_consolidated['Model'] = clf
df_consolidated['F1_Score'] = f1

print(f"Escore F1 médio: {f1:.4f}")

# Visualização da árvore de decisão
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True,
                feature_names=X.columns, class_names=['1', '2', '3'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('behavior.png')
Image(graph.create_png())

# Exibir DataFrame consolidado
print(df_consolidated.head())
